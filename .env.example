# LLM Provider Configuration
LLM_PROVIDER=gemini  # Options: gemini, openai, anthropic
GEMINI_API_KEY=your_gemini_api_key_here
OPENAI_API_KEY=your_openai_api_key_here  # Optional fallback
ANTHROPIC_API_KEY=your_anthropic_api_key_here  # Optional fallback

# Gemini Model Configuration
GEMINI_MODEL=gemini-1.5-flash  # Options: gemini-1.5-pro, gemini-1.5-flash
GEMINI_TEMPERATURE=0.3
GEMINI_MAX_TOKENS=2048

# Bitbucket Configuration
BITBUCKET_WORKSPACE=your_workspace
BITBUCKET_REPO_SLUG=your_repo
BITBUCKET_USERNAME=your_username
BITBUCKET_APP_PASSWORD=your_app_password
BITBUCKET_WEBHOOK_SECRET=your_webhook_secret

# Vector Store Configuration
VECTOR_STORE_TYPE=chromadb  # Options: chromadb, faiss
CHROMA_PERSIST_DIR=./vector_store
EMBEDDING_MODEL=models/embedding-001  # Gemini embedding model

# Application Configuration
API_HOST=0.0.0.0
API_PORT=8000
LOG_LEVEL=INFO
RULES_DIR=./rules

# Retrieval Configuration
TOP_K_RULES=10
SIMILARITY_THRESHOLD=0.7
CHUNK_SIZE=800
CHUNK_OVERLAP=100

# Review Configuration
MAX_RETRIES=3
RETRY_DELAY=2
REVIEW_TIMEOUT=120
